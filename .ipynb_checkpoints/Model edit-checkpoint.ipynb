{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af59945a-36e2-482b-9c58-9bfc87f0a483",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stations: 5\n",
      "Sea level shape (time x stations): (622392, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>station_name</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>sea_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1950-01-01 00:00:00.000000</td>\n",
       "      <td>Annapolis</td>\n",
       "      <td>38.98328</td>\n",
       "      <td>-76.4816</td>\n",
       "      <td>1.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1950-01-01 00:59:59.999997</td>\n",
       "      <td>Annapolis</td>\n",
       "      <td>38.98328</td>\n",
       "      <td>-76.4816</td>\n",
       "      <td>1.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1950-01-01 02:00:00.000003</td>\n",
       "      <td>Annapolis</td>\n",
       "      <td>38.98328</td>\n",
       "      <td>-76.4816</td>\n",
       "      <td>1.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1950-01-01 03:00:00.000000</td>\n",
       "      <td>Annapolis</td>\n",
       "      <td>38.98328</td>\n",
       "      <td>-76.4816</td>\n",
       "      <td>1.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1950-01-01 03:59:59.999997</td>\n",
       "      <td>Annapolis</td>\n",
       "      <td>38.98328</td>\n",
       "      <td>-76.4816</td>\n",
       "      <td>1.341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        time station_name  latitude  longitude  sea_level\n",
       "0 1950-01-01 00:00:00.000000    Annapolis  38.98328   -76.4816      1.341\n",
       "1 1950-01-01 00:59:59.999997    Annapolis  38.98328   -76.4816      1.311\n",
       "2 1950-01-01 02:00:00.000003    Annapolis  38.98328   -76.4816      1.280\n",
       "3 1950-01-01 03:00:00.000000    Annapolis  38.98328   -76.4816      1.280\n",
       "4 1950-01-01 03:59:59.999997    Annapolis  38.98328   -76.4816      1.341"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# Install & Import Dependencies\n",
    "# ============================================\n",
    "# !pip install scipy pandas\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# ============================================\n",
    "# Helper Function: MATLAB datenum → datetime\n",
    "# ============================================\n",
    "def matlab2datetime(matlab_datenum):\n",
    "    return datetime.fromordinal(int(matlab_datenum)) \\\n",
    "           + timedelta(days=matlab_datenum % 1) \\\n",
    "           - timedelta(days=366)\n",
    "\n",
    "# ============================================s\n",
    "# Load .mat Dataset\n",
    "# ============================================\n",
    "data = loadmat('NEUSTG_19502020_12stations.mat')\n",
    "\n",
    "lat = data['lattg'].flatten()\n",
    "lon = data['lontg'].flatten()\n",
    "sea_level = data['sltg']\n",
    "station_names = [s[0] for s in data['sname'].flatten()]\n",
    "time = data['t'].flatten()\n",
    "time_dt = np.array([matlab2datetime(t) for t in time])\n",
    "\n",
    "# ============================================\n",
    "# Select Target Stations\n",
    "# ============================================\n",
    "SELECTED_STATIONS = [\n",
    "    'Annapolis', 'Atlantic_City', 'Charleston', 'Washington', 'Wilmington'\n",
    "]\n",
    "\n",
    "selected_idx = [station_names.index(st) for st in SELECTED_STATIONS]\n",
    "selected_names = [station_names[i] for i in selected_idx]\n",
    "selected_lat = lat[selected_idx]\n",
    "selected_lon = lon[selected_idx]\n",
    "selected_sea_level = sea_level[:, selected_idx]  # time × selected_stations\n",
    "\n",
    "# ============================================\n",
    "# Build Preview DataFrame\n",
    "# ============================================\n",
    "df_preview = pd.DataFrame({\n",
    "    'time': np.tile(time_dt[:5], len(selected_names)),\n",
    "    'station_name': np.repeat(selected_names, 5),\n",
    "    'latitude': np.repeat(selected_lat, 5),\n",
    "    'longitude': np.repeat(selected_lon, 5),\n",
    "    'sea_level': selected_sea_level[:5, :].T.flatten()\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# Print Data Head\n",
    "# ============================================\n",
    "print(f\"Number of stations: {len(selected_names)}\")\n",
    "print(f\"Sea level shape (time x stations): {selected_sea_level.shape}\")\n",
    "df_preview.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba30fb02-18f1-4fdd-9db6-b6e63692ff7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_name</th>\n",
       "      <th>time</th>\n",
       "      <th>sea_level</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>flood_threshold</th>\n",
       "      <th>sea_level_max</th>\n",
       "      <th>flood</th>\n",
       "      <th>sea_level_3d_mean</th>\n",
       "      <th>sea_level_7d_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Annapolis</td>\n",
       "      <td>1950-01-01</td>\n",
       "      <td>1.471958</td>\n",
       "      <td>38.98328</td>\n",
       "      <td>-76.4816</td>\n",
       "      <td>2.396988</td>\n",
       "      <td>2.067</td>\n",
       "      <td>0</td>\n",
       "      <td>1.471958</td>\n",
       "      <td>1.471958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annapolis</td>\n",
       "      <td>1950-01-02</td>\n",
       "      <td>1.455417</td>\n",
       "      <td>38.98328</td>\n",
       "      <td>-76.4816</td>\n",
       "      <td>2.396988</td>\n",
       "      <td>2.505</td>\n",
       "      <td>1</td>\n",
       "      <td>1.463687</td>\n",
       "      <td>1.463687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annapolis</td>\n",
       "      <td>1950-01-03</td>\n",
       "      <td>1.841542</td>\n",
       "      <td>38.98328</td>\n",
       "      <td>-76.4816</td>\n",
       "      <td>2.396988</td>\n",
       "      <td>2.536</td>\n",
       "      <td>1</td>\n",
       "      <td>1.589639</td>\n",
       "      <td>1.589639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Annapolis</td>\n",
       "      <td>1950-01-04</td>\n",
       "      <td>1.396750</td>\n",
       "      <td>38.98328</td>\n",
       "      <td>-76.4816</td>\n",
       "      <td>2.396988</td>\n",
       "      <td>1.737</td>\n",
       "      <td>0</td>\n",
       "      <td>1.564569</td>\n",
       "      <td>1.541417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Annapolis</td>\n",
       "      <td>1950-01-05</td>\n",
       "      <td>1.704333</td>\n",
       "      <td>38.98328</td>\n",
       "      <td>-76.4816</td>\n",
       "      <td>2.396988</td>\n",
       "      <td>2.292</td>\n",
       "      <td>0</td>\n",
       "      <td>1.647542</td>\n",
       "      <td>1.574000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  station_name       time  sea_level  latitude  longitude  flood_threshold  \\\n",
       "0    Annapolis 1950-01-01   1.471958  38.98328   -76.4816         2.396988   \n",
       "1    Annapolis 1950-01-02   1.455417  38.98328   -76.4816         2.396988   \n",
       "2    Annapolis 1950-01-03   1.841542  38.98328   -76.4816         2.396988   \n",
       "3    Annapolis 1950-01-04   1.396750  38.98328   -76.4816         2.396988   \n",
       "4    Annapolis 1950-01-05   1.704333  38.98328   -76.4816         2.396988   \n",
       "\n",
       "   sea_level_max  flood  sea_level_3d_mean  sea_level_7d_mean  \n",
       "0          2.067      0           1.471958           1.471958  \n",
       "1          2.505      1           1.463687           1.463687  \n",
       "2          2.536      1           1.589639           1.589639  \n",
       "3          1.737      0           1.564569           1.541417  \n",
       "4          2.292      0           1.647542           1.574000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ============================================\n",
    "# Convert Hourly → Daily per Station\n",
    "# ============================================\n",
    "# Convert time to pandas datetime\n",
    "time_dt = pd.to_datetime(time_dt)\n",
    "\n",
    "# Build hourly DataFrame for selected stations\n",
    "df_hourly = pd.DataFrame({\n",
    "    'time': np.tile(time_dt, len(selected_names)),\n",
    "    'station_name': np.repeat(selected_names, len(time_dt)),\n",
    "    'latitude': np.repeat(selected_lat, len(time_dt)),\n",
    "    'longitude': np.repeat(selected_lon, len(time_dt)),\n",
    "    'sea_level': selected_sea_level.flatten()\n",
    "})\n",
    "\n",
    "# ============================================\n",
    "# Compute Flood Threshold per Station\n",
    "# ============================================\n",
    "threshold_df = df_hourly.groupby('station_name')['sea_level'].agg(['mean','std']).reset_index()\n",
    "threshold_df['flood_threshold'] = threshold_df['mean'] + 1.5 * threshold_df['std']\n",
    "\n",
    "df_hourly = df_hourly.merge(threshold_df[['station_name','flood_threshold']], on='station_name', how='left')\n",
    "\n",
    "# ============================================\n",
    "# Daily Aggregation + Flood Flag\n",
    "# ============================================\n",
    "df_daily = df_hourly.groupby(['station_name', pd.Grouper(key='time', freq='D')]).agg({\n",
    "    'sea_level': 'mean',\n",
    "    'latitude': 'first',\n",
    "    'longitude': 'first',\n",
    "    'flood_threshold': 'first'\n",
    "}).reset_index()\n",
    "\n",
    "# Flood flag: 1 if any hourly value exceeded threshold that day\n",
    "hourly_max = df_hourly.groupby(['station_name', pd.Grouper(key='time', freq='D')])['sea_level'].max().reset_index()\n",
    "df_daily = df_daily.merge(hourly_max, on=['station_name','time'], suffixes=('','_max'))\n",
    "df_daily['flood'] = (df_daily['sea_level_max'] > df_daily['flood_threshold']).astype(int)\n",
    "\n",
    "# ============================================\n",
    "# Feature Engineering (3d & 7d means)\n",
    "# ============================================\n",
    "df_daily['sea_level_3d_mean'] = df_daily.groupby('station_name')['sea_level'].transform(\n",
    "    lambda x: x.rolling(3, min_periods=1).mean())\n",
    "df_daily['sea_level_7d_mean'] = df_daily.groupby('station_name')['sea_level'].transform(\n",
    "    lambda x: x.rolling(7, min_periods=1).mean())\n",
    "\n",
    "# Preview\n",
    "df_daily.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507ab71-2d8f-4061-ab9e-23bd90ad4213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Using device: cpu\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# LSTM Approach with PyTorch\n",
    "# ============================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# Reshape Data for LSTM (Sequence Format)\n",
    "# ============================================\n",
    "FEATURES = ['sea_level', 'sea_level_3d_mean', 'sea_level_7d_mean']\n",
    "HIST_DAYS = 7\n",
    "FUTURE_DAYS = 14\n",
    "\n",
    "X_train_lstm, y_train_lstm = [], []\n",
    "\n",
    "for stn, grp in df_daily.groupby('station_name'):\n",
    "    grp = grp.sort_values('time').reset_index(drop=True)\n",
    "    for i in range(len(grp) - HIST_DAYS - FUTURE_DAYS):\n",
    "        # Keep sequence structure: (7 days, 3 features)\n",
    "        hist = grp.loc[i:i+HIST_DAYS-1, FEATURES].values  # Shape: (7, 3)\n",
    "        future = grp.loc[i+HIST_DAYS:i+HIST_DAYS+FUTURE_DAYS-1, 'flood'].values\n",
    "        X_train_lstm.append(hist)\n",
    "        y_train_lstm.append(future)\n",
    "\n",
    "X_train_lstm = np.array(X_train_lstm)  # Shape: (samples, 7, 3)\n",
    "y_train_lstm = np.array(y_train_lstm)  # Shape: (samples, 14)\n",
    "\n",
    "print(f\"LSTM Training Data Shapes:\")\n",
    "print(f\"X_train_lstm: {X_train_lstm.shape} (samples, sequence_length, features)\")\n",
    "print(f\"y_train_lstm: {y_train_lstm.shape} (samples, future_days)\\n\")\n",
    "\n",
    "# Normalize features for LSTM\n",
    "scaler = StandardScaler()\n",
    "n_samples, n_timesteps, n_features = X_train_lstm.shape\n",
    "X_train_lstm_reshaped = X_train_lstm.reshape(-1, n_features)\n",
    "X_train_lstm_scaled = scaler.fit_transform(X_train_lstm_reshaped)\n",
    "X_train_lstm = X_train_lstm_scaled.reshape(n_samples, n_timesteps, n_features)\n",
    "\n",
    "# Prepare test data for LSTM\n",
    "X_test_lstm = []\n",
    "for stn, grp in df_daily.groupby('station_name'):\n",
    "    mask = (grp['time'] >= hist_start) & (grp['time'] <= hist_end)\n",
    "    hist_block = grp.loc[mask, FEATURES].values\n",
    "    if len(hist_block) == 7:  # ensure full 7-day block\n",
    "        X_test_lstm.append(hist_block)\n",
    "\n",
    "X_test_lstm = np.array(X_test_lstm)  # Shape: (stations, 7, 3)\n",
    "\n",
    "# Normalize test data with same scaler\n",
    "n_test_samples, n_test_timesteps, n_test_features = X_test_lstm.shape\n",
    "X_test_lstm_reshaped = X_test_lstm.reshape(-1, n_test_features)\n",
    "X_test_lstm_scaled = scaler.transform(X_test_lstm_reshaped)\n",
    "X_test_lstm = X_test_lstm_scaled.reshape(n_test_samples, n_test_timesteps, n_test_features)\n",
    "\n",
    "print(f\"X_test_lstm shape: {X_test_lstm.shape}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# PyTorch Dataset Class\n",
    "# ============================================\n",
    "class FloodDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.FloatTensor(X)\n",
    "        self.y = torch.FloatTensor(y)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "\n",
    "# Create datasets and data loaders\n",
    "train_dataset = FloodDataset(X_train_lstm, y_train_lstm)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# ============================================\n",
    "# LSTM Model Architecture\n",
    "# ============================================\n",
    "class FloodLSTM(nn.Module):\n",
    "    def __init__(self, input_size=3, hidden_size=64, num_layers=4, output_size=14, dropout=0.2):\n",
    "        super(FloodLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # LSTM layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size,\n",
    "            hidden_size=hidden_size,\n",
    "            num_layers=num_layers,\n",
    "            batch_first=True,\n",
    "            dropout=dropout if num_layers > 1 else 0,\n",
    "            bidirectional=False\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(hidden_size, 32)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc2 = nn.Linear(32, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, sequence_length, features)\n",
    "        # LSTM forward pass\n",
    "        lstm_out, (h_n, c_n) = self.lstm(x)\n",
    "        \n",
    "        # Use the last timestep output\n",
    "        last_output = lstm_out[:, -1, :]  # Shape: (batch, hidden_size)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        out = self.fc1(last_output)\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.sigmoid(out)  # Output probabilities for each of 14 days\n",
    "        \n",
    "        return out\n",
    "\n",
    "# ============================================\n",
    "# Initialize Model, Loss, Optimizer\n",
    "# ============================================\n",
    "model = FloodLSTM(\n",
    "    input_size=3,\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    output_size=14,\n",
    "    dropout=0.2\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5, verbose=True)\n",
    "\n",
    "print(f\"Model Architecture:\")\n",
    "print(model)\n",
    "print(f\"\\nTotal parameters: {sum(p.numel() for p in model.parameters()):,}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# Training Loop\n",
    "# ============================================\n",
    "num_epochs = 30\n",
    "best_loss = float('inf')\n",
    "patience = 10\n",
    "patience_counter = 0\n",
    "\n",
    "print(\"Starting LSTM Training...\")\n",
    "print(f\"{'Epoch':<8} {'Train Loss':<12} {'LR':<10}\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch_X, batch_y in train_loader:\n",
    "        batch_X = batch_X.to(device)\n",
    "        batch_y = batch_y.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Gradient clipping\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    avg_loss = total_loss / num_batches\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Early stopping\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        patience_counter = 0\n",
    "        # Save best model\n",
    "        torch.save(model.state_dict(), 'best_lstm_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "    \n",
    "    if (epoch + 1) % 5 == 0 or epoch == 0:\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print(f\"{epoch+1:<8} {avg_loss:<12.6f} {current_lr:<10.6f}\")\n",
    "    \n",
    "    if patience_counter >= patience:\n",
    "        print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "print(\"\\nTraining completed!\")\n",
    "\n",
    "# Load best model\n",
    "model.load_state_dict(torch.load('best_lstm_model.pth'))\n",
    "model.eval()\n",
    "\n",
    "# ============================================\n",
    "# LSTM Predictions\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"LSTM Predictions\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "X_test_tensor = torch.FloatTensor(X_test_lstm).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred_lstm = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "y_pred_lstm_bin = (y_pred_lstm > 0.5).astype(int)\n",
    "\n",
    "print(f\"LSTM Predictions shape: {y_pred_lstm.shape}\")\n",
    "print(f\"Prediction probabilities (first station, first 5 days): {y_pred_lstm[0, :5]}\")\n",
    "print(f\"Binary predictions (first station, first 5 days): {y_pred_lstm_bin[0, :5]}\\n\")\n",
    "\n",
    "# ============================================\n",
    "# LSTM Evaluation\n",
    "# ============================================\n",
    "y_true_flat_lstm = y_true.flatten()\n",
    "y_pred_flat_lstm = y_pred_lstm_bin.flatten()\n",
    "\n",
    "tn_lstm, fp_lstm, fn_lstm, tp_lstm = confusion_matrix(y_true_flat_lstm, y_pred_flat_lstm).ravel()\n",
    "acc_lstm = accuracy_score(y_true_flat_lstm, y_pred_flat_lstm)\n",
    "f1_lstm = f1_score(y_true_flat_lstm, y_pred_flat_lstm)\n",
    "mcc_lstm = matthews_corrcoef(y_true_flat_lstm, y_pred_flat_lstm)\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"LSTM Results\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\n=== Confusion Matrix ===\")\n",
    "print(f\"TP: {tp_lstm} | FP: {fp_lstm} | TN: {tn_lstm} | FN: {fn_lstm}\")\n",
    "print(\"\\n=== Metrics ===\")\n",
    "print(f\"Accuracy: {acc_lstm:.3f}\")\n",
    "print(f\"F1 Score: {f1_lstm:.3f}\")\n",
    "print(f\"MCC: {mcc_lstm:.3f}\")\n",
    "\n",
    "# ============================================\n",
    "# Comparison: XGBoost vs LSTM\n",
    "# ============================================\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Model Comparison: XGBoost vs LSTM\")\n",
    "print(\"=\"*50)\n",
    "print(f\"\\n{'Metric':<15} {'XGBoost':<12} {'LSTM':<12} {'Difference':<12}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'Accuracy':<15} {acc:<12.3f} {acc_lstm:<12.3f} {acc_lstm-acc:<+12.3f}\")\n",
    "print(f\"{'F1 Score':<15} {f1:<12.3f} {f1_lstm:<12.3f} {f1_lstm-f1:<+12.3f}\")\n",
    "print(f\"{'MCC':<15} {mcc:<12.3f} {mcc_lstm:<12.3f} {mcc_lstm-mcc:<+12.3f}\")\n",
    "print(f\"\\n{'True Positives':<15} {tp:<12} {tp_lstm:<12} {tp_lstm-tp:<+12}\")\n",
    "print(f\"{'False Positives':<15} {fp:<12} {fp_lstm:<12} {fp_lstm-fp:<+12}\")\n",
    "print(f\"{'True Negatives':<15} {tn:<12} {tn_lstm:<12} {tn_lstm-tn:<+12}\")\n",
    "print(f\"{'False Negatives':<15} {fn:<12} {fn_lstm:<12} {fn_lstm-fn:<+12}\")\n",
    "\n",
    "# Save LSTM predictions for further analysis\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Saved files:\")\n",
    "print(\"  - best_lstm_model.pth (PyTorch model state)\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d10cd5-b2b3-48ac-99ea-7efa4a7b2846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
